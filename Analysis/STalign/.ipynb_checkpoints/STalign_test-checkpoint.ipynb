{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3ce8f4-073a-4b30-ac6a-c3a4b8526b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================== ERROR ======================\n",
      "FAILURE: Cell data error: Error tokenizing data. C error: Expected 44 fields in line 5372168, saw 60\n",
      "\n",
      "\n",
      "Troubleshooting steps:\n",
      "1. Try increasing 'max_split_size' parameter\n",
      "2. Reduce 'batch_size' in PARAMS['batch']\n",
      "3. Increase 'raster_resolution' in main PARAMS\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cell data error: Error tokenizing data. C error: Expected 44 fields in line 5372168, saw 60\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mload_cell_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     required = [\u001b[33m'\u001b[39m\u001b[33mX_centroid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mY_centroid\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    910\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:583\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1704\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1699\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1700\u001b[39m     (\n\u001b[32m   1701\u001b[39m         index,\n\u001b[32m   1702\u001b[39m         columns,\n\u001b[32m   1703\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:812\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:873\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:848\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:859\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/STalign-env/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:2025\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 44 fields in line 5372168, saw 60\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 291\u001b[39m\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 251\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    248\u001b[39m XI = np.arange(he_data.shape[\u001b[32m2\u001b[39m]) * \u001b[32m1.0\u001b[39m\n\u001b[32m    249\u001b[39m he_image = {\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m: he_data, \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: XI, \u001b[33m'\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m: YI}\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m df, x_coords, y_coords = \u001b[43mload_cell_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATHS\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcell_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# Rasterize cells\u001b[39;00m\n\u001b[32m    254\u001b[39m XJ, YJ, rasterized = rasterize_cells(x_coords, y_coords, PARAMS[\u001b[33m'\u001b[39m\u001b[33mraster_resolution\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 92\u001b[39m, in \u001b[36mload_cell_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df, np.array(df[\u001b[33m'\u001b[39m\u001b[33mX_centroid\u001b[39m\u001b[33m'\u001b[39m]), np.array(df[\u001b[33m'\u001b[39m\u001b[33mY_centroid\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCell data error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Cell data error: Error tokenizing data. C error: Expected 44 fields in line 5372168, saw 60\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STalign-based H&E to t-CycIF Alignment Pipeline\n",
    "With GPU Memory Optimizations and Batch Processing\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy.ndimage as ndimage\n",
    "from pathlib import Path\n",
    "from STalign import STalign\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration - Update these paths as needed\n",
    "PATHS = {\n",
    "    'he_image': Path(r\"/media/cruz-osuna/TOSHIBA EXT/virtual_tma/ONCOSYS-OVA_try2/H144_iOme2_PE_II_HE.png\"),\n",
    "    'cell_data': Path(r\"/media/cruz-osuna/TOSHIBA EXT/virtual_tma/ONCOSYS-OVA_try2/cell_data.csv\"),\n",
    "    'landmarks_he': Path(r\"/media/cruz-osuna/TOSHIBA EXT/virtual_tma/ONCOSYS-OVA_try2/landmarks/H144_iOmeHE_points.npy\"),\n",
    "    'landmarks_cycif': Path(r\"/media/cruz-osuna/TOSHIBA EXT/virtual_tma/ONCOSYS-OVA_try2/landmarks/H144_iOme_points.npy\"),\n",
    "    'output': Path(r\"/media/cruz-osuna/TOSHIBA EXT/virtual_tma/ONCOSYS-OVA_try2/output/H144_iOme2_PE_II.csv.gz\")\n",
    "}\n",
    "\n",
    "PARAMS = {\n",
    "    'rotation': 90,\n",
    "    'raster_resolution': 10,\n",
    "    'lddmm': {\n",
    "        'sigmaM': 0.15,\n",
    "        'sigmaB': 0.10,\n",
    "        'sigmaA': 0.11,\n",
    "        'epV': 10,\n",
    "        'niter': 2000\n",
    "    },\n",
    "    'batch': {\n",
    "        'size': 5000,\n",
    "        'max_split_size': 128\n",
    "    }\n",
    "}\n",
    "\n",
    "def validate_paths():\n",
    "    \"\"\"Validate all paths before processing\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for key in ['he_image', 'cell_data', 'landmarks_he', 'landmarks_cycif']:\n",
    "        path = PATHS[key]\n",
    "        if not path.exists():\n",
    "            errors.append(f\"Missing input file: {str(path)}\")\n",
    "        elif path.is_dir():\n",
    "            errors.append(f\"Expected file but found directory: {str(path)}\")\n",
    "\n",
    "    output_dir = PATHS['output'].parent\n",
    "    if not output_dir.exists():\n",
    "        errors.append(f\"Output directory does not exist: {str(output_dir)}\\nCreate it with:\\nmkdir -p '{str(output_dir)}'\")\n",
    "    elif not os.access(output_dir, os.W_OK):\n",
    "        errors.append(f\"Output directory not writable: {str(output_dir)}\\nCheck permissions with:\\nls -ld '{str(output_dir)}'\")\n",
    "\n",
    "    if errors:\n",
    "        raise RuntimeError(\"\\n\".join(errors))\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU settings for optimal memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = f'max_split_size_mb:{PARAMS[\"batch\"][\"max_split_size\"]}'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def load_he_image(path, rotation=0):\n",
    "    \"\"\"Load and preprocess H&E image with memory optimization\"\"\"\n",
    "    try:\n",
    "        img = plt.imread(str(path))\n",
    "        if rotation != 0:\n",
    "            img = ndimage.rotate(img, rotation, reshape=True)\n",
    "        return STalign.normalize(img.transpose(2,0,1))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading H&E image: {str(e)}\")\n",
    "\n",
    "def load_cell_data(path):\n",
    "    \"\"\"Load single-cell data with validation and error handling\"\"\"\n",
    "    try:\n",
    "        # Handle bad lines and quoted fields\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            on_bad_lines='warn',  # Skip problematic lines with warning\n",
    "            quoting=csv.QUOTE_MINIMAL,\n",
    "            quotechar='\"',\n",
    "            engine='python'  # More flexible parser for messy files\n",
    "        )\n",
    "        \n",
    "        required = ['X_centroid', 'Y_centroid']\n",
    "        missing = [col for col in required if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns: {', '.join(missing)}\")\n",
    "            \n",
    "        return df, np.array(df['X_centroid']), np.array(df['Y_centroid'])\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Cell data error: {str(e)}\")\n",
    "\n",
    "def rasterize_cells(x, y, resolution=5):\n",
    "    \"\"\"Convert coordinates to rasterized image\"\"\"\n",
    "    XJ, YJ, M, fig = STalign.rasterize(x, y, dx=resolution)\n",
    "    fig.axes[0].invert_yaxis()\n",
    "    J = np.vstack((M, M, M))\n",
    "    return XJ, YJ, STalign.normalize(J)\n",
    "\n",
    "def load_landmarks(path):\n",
    "    \"\"\"Load and convert landmark points\"\"\"\n",
    "    points = np.load(str(path), allow_pickle=True).tolist()\n",
    "    formatted = []\n",
    "    for k in points.keys():\n",
    "        formatted.append([points[k][0][1], points[k][0][0]])\n",
    "    return np.array(formatted)\n",
    "\n",
    "def initialize_alignment(points_he, points_cycif):\n",
    "    \"\"\"Calculate initial affine transformation\"\"\"\n",
    "    L, T = STalign.L_T_from_points(points_he, points_cycif)\n",
    "    return L, T\n",
    "\n",
    "\n",
    "def batch_transform_points(xv, v, A, points, batch_size=5000):\n",
    "    \"\"\"Transform points in batches with dtype consistency\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    all_coords = []\n",
    "    \n",
    "    # Ensure transformation parameters are on correct device and dtype\n",
    "    def ensure_tensor(param, device):\n",
    "        if isinstance(param, (list, tuple)):\n",
    "            return [ensure_tensor(p, device) for p in param]\n",
    "        if not isinstance(param, torch.Tensor):\n",
    "            param = torch.tensor(param, device=device, dtype=torch.float64)\n",
    "        return param.to(dtype=torch.float64, device=device)\n",
    "    \n",
    "    xv = ensure_tensor(xv, device)\n",
    "    v = ensure_tensor(v, device)\n",
    "    A = ensure_tensor(A, device)\n",
    "\n",
    "    for i in range(0, len(points), batch_size):\n",
    "        # Keep original float64 dtype from CSV data\n",
    "        batch_points = points[i:i+batch_size]\n",
    "        points_tensor = torch.from_numpy(batch_points).to(\n",
    "            device=device,\n",
    "            dtype=torch.float64  # Maintain float64 precision\n",
    "        )\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=False):  # Disable mixed precision\n",
    "            batch_coords = STalign.transform_points_target_to_source(\n",
    "                xv, \n",
    "                v, \n",
    "                A, \n",
    "                points_tensor\n",
    "            )\n",
    "            all_coords.append(batch_coords.detach().cpu().numpy())\n",
    "            \n",
    "        del points_tensor, batch_coords\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return np.concatenate(all_coords)\n",
    "\n",
    "\n",
    "def perform_lddmm_alignment(he_image, cycif_image, L, T, params):\n",
    "    \"\"\"Perform optimized non-linear alignment\"\"\"\n",
    "    configure_gpu()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Filter valid LDDMM parameters\n",
    "    valid_params = {k: v for k, v in params.items() if k in ['sigmaM', 'sigmaB', 'sigmaA', 'epV', 'niter']}\n",
    "    \n",
    "    L_tensor = torch.from_numpy(L).float().to(device)\n",
    "    T_tensor = torch.from_numpy(T).float().to(device)\n",
    "    \n",
    "    he_data = torch.from_numpy(he_image['data']).half().to(device)\n",
    "    cycif_data = torch.from_numpy(cycif_image['data']).half().to(device)\n",
    "\n",
    "    base_params = {\n",
    "        'L': L_tensor,\n",
    "        'T': T_tensor,\n",
    "        'device': device,\n",
    "        'muB': torch.tensor([0, 0, 0], dtype=torch.float16, device=device),\n",
    "        'muA': torch.tensor([1, 1, 1], dtype=torch.float16, device=device)\n",
    "    }\n",
    "    base_params.update(valid_params)\n",
    "    \n",
    "    try:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return STalign.LDDMM(\n",
    "                [he_image['Y'], he_image['X']], he_data,\n",
    "                [cycif_image['Y'], cycif_image['X']], cycif_data,\n",
    "                **base_params\n",
    "            )\n",
    "    except RuntimeError as e:\n",
    "        if 'CUDA out of memory' in str(e):\n",
    "            print(\"Falling back to CPU with reduced resolution\")\n",
    "            return perform_cpu_fallback(he_image, cycif_image, L, T, params)\n",
    "        raise\n",
    "\n",
    "def perform_cpu_fallback(he_image, cycif_image, L, T, params):\n",
    "    \"\"\"CPU fallback implementation with reduced resolution\"\"\"\n",
    "    params['raster_resolution'] *= 2\n",
    "    XJ, YJ, rasterized = rasterize_cells(\n",
    "        cycif_image['X'], cycif_image['Y'], \n",
    "        params['raster_resolution']\n",
    "    )\n",
    "    \n",
    "    he_data = torch.from_numpy(he_image['data']).float()\n",
    "    cycif_data = torch.from_numpy(rasterized).float()\n",
    "    \n",
    "    return STalign.LDDMM(\n",
    "        [he_image['Y'], he_image['X']], he_data,\n",
    "        [YJ, XJ], cycif_data,\n",
    "        L=L, T=T,\n",
    "        device='cpu',\n",
    "        niter=params.get('niter', 1000)\n",
    "    )\n",
    "\n",
    "def save_results(df, transformed_coords, output_path):\n",
    "    \"\"\"Save results with automatic directory creation\"\"\"\n",
    "    try:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df['aligned_X'] = transformed_coords[:, 1]\n",
    "        df['aligned_Y'] = transformed_coords[:, 0]\n",
    "        \n",
    "        if output_path.suffix == '.gz':\n",
    "            df.to_csv(output_path, compression='gzip', index=False)\n",
    "        else:\n",
    "            df.to_csv(output_path, index=False)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to save results: {str(e)}\")\n",
    "\n",
    "def visualize_alignment(he_image, original, transformed, output_dir):\n",
    "    \"\"\"Generate alignment visualization\"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    ax[0].imshow(he_image['data'].transpose(1, 2, 0), extent=STalign.extent_from_x((he_image['Y'], he_image['X'])))\n",
    "    ax[0].scatter(original[:, 0], original[:, 1], s=1, alpha=0.1, c='red')\n",
    "    ax[0].set_title('Original Positions')\n",
    "    \n",
    "    ax[1].imshow(he_image['data'].transpose(1, 2, 0), extent=STalign.extent_from_x((he_image['Y'], he_image['X'])))\n",
    "    ax[1].scatter(transformed[:, 1], transformed[:, 0], s=1, alpha=0.1, c='white')\n",
    "    ax[1].set_title('Aligned Positions')\n",
    "    \n",
    "    plt.savefig(output_dir/'alignment_result.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        validate_paths()\n",
    "        configure_gpu()\n",
    "        \n",
    "        # Load data\n",
    "        he_data = load_he_image(PATHS['he_image'], PARAMS['rotation'])\n",
    "        YI = np.arange(he_data.shape[1]) * 1.0\n",
    "        XI = np.arange(he_data.shape[2]) * 1.0\n",
    "        he_image = {'data': he_data, 'X': XI, 'Y': YI}\n",
    "        \n",
    "        df, x_coords, y_coords = load_cell_data(PATHS['cell_data'])\n",
    "        \n",
    "        # Rasterize cells\n",
    "        XJ, YJ, rasterized = rasterize_cells(x_coords, y_coords, PARAMS['raster_resolution'])\n",
    "        cycif_image = {'data': rasterized, 'X': XJ, 'Y': YJ}\n",
    "        \n",
    "        # Alignment\n",
    "        points_he = load_landmarks(PATHS['landmarks_he'])\n",
    "        points_cycif = load_landmarks(PATHS['landmarks_cycif'])\n",
    "        L, T = initialize_alignment(points_he, points_cycif)\n",
    "        \n",
    "        result = perform_lddmm_alignment(he_image, cycif_image, L, T, PARAMS['lddmm'])\n",
    "        \n",
    "        # Batch transformation\n",
    "        points = np.stack([y_coords, x_coords], -1)\n",
    "        transformed_coords = batch_transform_points(\n",
    "            result['xv'], \n",
    "            result['v'], \n",
    "            result['A'],\n",
    "            points,\n",
    "            PARAMS['batch']['size']\n",
    "        )\n",
    "        \n",
    "        # Save and visualize\n",
    "        save_results(df, transformed_coords, PATHS['output'])\n",
    "        visualize_alignment(he_image, points, transformed_coords, PATHS['output'].parent)\n",
    "        \n",
    "        print(\"\\nSUCCESS: Alignment completed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{' ERROR '.center(50, '=')}\")\n",
    "        print(f\"FAILURE: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(f\"1. Try increasing 'max_split_size' parameter\")\n",
    "        print(f\"2. Reduce 'batch_size' in PARAMS['batch']\")\n",
    "        print(f\"3. Increase 'raster_resolution' in main PARAMS\")\n",
    "        print('='*50)\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c2b3c-9f0f-48e7-89b2-2a77a9505a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
