{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dce0116-f9d7-47ac-a98b-0703c74dbfae",
   "metadata": {},
   "source": [
    "# Installation and use of STalign\n",
    "\n",
    "Cruz Osuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a226c-8306-4ca8-9a6e-f327dc91d20d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "\n",
    "` conda create --name STalign-env python=3.11` \n",
    "\n",
    "` conda activate STalign-env` \n",
    "\n",
    "` pip install --upgrade \"git+https://github.com/JEFworks-Lab/STalign.git\"` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f13f3-3a45-4126-b8d3-b86c3739c1bd",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f1ff6-9f1d-4268-a060-737bec4ccab8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create the .npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd447c-0852-4aea-8998-e9c784bc3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy.ndimage as ndimage\n",
    "from STalign import STalign\n",
    "\n",
    "# Parámetros\n",
    "image_file = \"T:/virtual_tma/FA/Images/FAHNSCC-14_he.png\"\n",
    "csv_file = \"T:/CycIF_human_2024/8_Results/Datasets/2_2_Phenotype_calling/FAHNSCC_14_phenotype_annotated.csv\"\n",
    "output_npz_image = \"T:/virtual_tma/FA/Points/npz/FAHNSCC_14\"\n",
    "output_npz_raster = \"T:/virtual_tma/FA/Points/npz/FAHNSCC_14_HE\"\n",
    "rotation_angle = 90  # grados\n",
    "dx = 5  # resolución de rasterización en µm\n",
    "\n",
    "# Leer imagen H&E\n",
    "V = plt.imread(image_file)\n",
    "V = ndimage.rotate(V, rotation_angle, reshape=True)\n",
    "\n",
    "# Visualizar imagen (opcional)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(V)\n",
    "\n",
    "# Transformar imagen a formato 3xNxM para STalign\n",
    "Inorm = V\n",
    "I = Inorm.transpose(2, 0, 1)\n",
    "YI = np.array(range(I.shape[1])) * 1.0\n",
    "XI = np.array(range(I.shape[2])) * 1.0\n",
    "extentI = STalign.extent_from_x((YI, XI))\n",
    "\n",
    "# Leer datos de células\n",
    "df = pd.read_csv(csv_file)\n",
    "xM = np.array(df['X_centroid'])\n",
    "yM = np.array(df['Y_centroid'])\n",
    "\n",
    "# Rasterizar puntos celulares a imagen\n",
    "XJ, YJ, M, fig = STalign.rasterize(xM, yM, dx=dx)\n",
    "ax = fig.axes[0]\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Convertir raster a imagen RGB simulada y normalizar\n",
    "J = np.vstack((M, M, M))\n",
    "J = STalign.normalize(J)\n",
    "\n",
    "# Verificar dimensiones\n",
    "print(\"Imagen H&E (I):\", I.shape)\n",
    "print(\"Imagen rasterizada (M):\", M.shape)\n",
    "print(\"Imagen RGB rasterizada (J):\", J.shape)\n",
    "\n",
    "# Guardar imágenes como .npz\n",
    "np.savez(output_npz_image, x=XI, y=YI, I=I)\n",
    "np.savez(output_npz_raster, x=XJ, y=YJ, I=J)\n",
    "\n",
    "# Visualización de puntos celulares (opcional)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xM, yM, s=1, alpha=0.2)\n",
    "plt.title(\"Distribución de células\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f7393-1351-4482-bf44-6150073d7e2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create the landmarck points\n",
    "\n",
    "Use the `point_annotator.py` script to generate the .npy files using the .npz files.\n",
    "\n",
    "`python point_annotator.py /path/H&E_image.npz /path/t-CycIF_image.npz` \n",
    "\n",
    "\n",
    "\n",
    "Example: \n",
    "\n",
    "` python point_annotator.py /media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/landmarcks/FAHNSCC_14_HE.npz /media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/landmarcks/FAHNSCC_14.npz`  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f1c828-6efc-4cf0-8d84-f08fbd70e38d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Run the alignement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3ce8f4-073a-4b30-ac6a-c3a4b8526b71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSTalign-based H&E to t-CycIF Alignment Pipeline\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mWith GPU Memory Optimizations and Batch Processing\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STalign-based H&E to t-CycIF Alignment Pipeline\n",
    "With GPU Memory Optimizations and Batch Processing\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy.ndimage as ndimage\n",
    "from pathlib import Path\n",
    "from STalign import STalign\n",
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration - Update these paths as needed\n",
    "PATHS = {\n",
    "    'he_image': Path(r\"/media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/FAHNSCC-14_H&E.png\"),\n",
    "    'cell_data': Path(r\"/media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/cell_data.csv\"),\n",
    "    'landmarks_he': Path(r\"/media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/landmarcks/FAHNSCC_14_HE_points.npy\"),\n",
    "    'landmarks_cycif': Path(r\"/media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/landmarcks/FAHNSCC_14_points.npy\"),\n",
    "    'output': Path(r\"/media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/output/FAHNSCC_14.csv.gz\")\n",
    "}\n",
    "\n",
    "PARAMS = {\n",
    "    'rotation': 90,\n",
    "    'raster_resolution': 10,\n",
    "    'lddmm': {\n",
    "        'sigmaM': 0.15,\n",
    "        'sigmaB': 0.10,\n",
    "        'sigmaA': 0.11,\n",
    "        'epV': 10,\n",
    "        'niter': 2000\n",
    "    },\n",
    "    'batch': {\n",
    "        'size': 5000,\n",
    "        'max_split_size': 128\n",
    "    }\n",
    "}\n",
    "\n",
    "def validate_paths():\n",
    "    \"\"\"Validate all paths before processing\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for key in ['he_image', 'cell_data', 'landmarks_he', 'landmarks_cycif']:\n",
    "        path = PATHS[key]\n",
    "        if not path.exists():\n",
    "            errors.append(f\"Missing input file: {str(path)}\")\n",
    "        elif path.is_dir():\n",
    "            errors.append(f\"Expected file but found directory: {str(path)}\")\n",
    "\n",
    "    output_dir = PATHS['output'].parent\n",
    "    if not output_dir.exists():\n",
    "        errors.append(f\"Output directory does not exist: {str(output_dir)}\\nCreate it with:\\nmkdir -p '{str(output_dir)}'\")\n",
    "    elif not os.access(output_dir, os.W_OK):\n",
    "        errors.append(f\"Output directory not writable: {str(output_dir)}\\nCheck permissions with:\\nls -ld '{str(output_dir)}'\")\n",
    "\n",
    "    if errors:\n",
    "        raise RuntimeError(\"\\n\".join(errors))\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU settings for optimal memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = f'max_split_size_mb:{PARAMS[\"batch\"][\"max_split_size\"]}'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def load_he_image(path, rotation=0):\n",
    "    \"\"\"Load and preprocess H&E image with memory optimization\"\"\"\n",
    "    try:\n",
    "        img = plt.imread(str(path))\n",
    "        if rotation != 0:\n",
    "            img = ndimage.rotate(img, rotation, reshape=True)\n",
    "        return STalign.normalize(img.transpose(2,0,1))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading H&E image: {str(e)}\")\n",
    "\n",
    "def load_cell_data(path):\n",
    "    \"\"\"Load single-cell data with validation and error handling\"\"\"\n",
    "    try:\n",
    "        # Handle bad lines and quoted fields\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            on_bad_lines='warn',  # Skip problematic lines with warning\n",
    "            quoting=csv.QUOTE_MINIMAL,\n",
    "            quotechar='\"',\n",
    "            engine='python'  # More flexible parser for messy files\n",
    "        )\n",
    "        \n",
    "        required = ['X_centroid', 'Y_centroid']\n",
    "        missing = [col for col in required if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns: {', '.join(missing)}\")\n",
    "            \n",
    "        return df, np.array(df['X_centroid']), np.array(df['Y_centroid'])\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Cell data error: {str(e)}\")\n",
    "\n",
    "def rasterize_cells(x, y, resolution=5):\n",
    "    \"\"\"Convert coordinates to rasterized image\"\"\"\n",
    "    XJ, YJ, M, fig = STalign.rasterize(x, y, dx=resolution)\n",
    "    fig.axes[0].invert_yaxis()\n",
    "    J = np.vstack((M, M, M))\n",
    "    return XJ, YJ, STalign.normalize(J)\n",
    "\n",
    "def load_landmarks(path):\n",
    "    \"\"\"Load and convert landmark points\"\"\"\n",
    "    points = np.load(str(path), allow_pickle=True).tolist()\n",
    "    formatted = []\n",
    "    for k in points.keys():\n",
    "        formatted.append([points[k][0][1], points[k][0][0]])\n",
    "    return np.array(formatted)\n",
    "\n",
    "def initialize_alignment(points_he, points_cycif):\n",
    "    \"\"\"Calculate initial affine transformation\"\"\"\n",
    "    L, T = STalign.L_T_from_points(points_he, points_cycif)\n",
    "    return L, T\n",
    "\n",
    "\n",
    "def batch_transform_points(xv, v, A, points, batch_size=5000):\n",
    "    \"\"\"Transform points in batches with dtype consistency\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    all_coords = []\n",
    "    \n",
    "    # Ensure transformation parameters are on correct device and dtype\n",
    "    def ensure_tensor(param, device):\n",
    "        if isinstance(param, (list, tuple)):\n",
    "            return [ensure_tensor(p, device) for p in param]\n",
    "        if not isinstance(param, torch.Tensor):\n",
    "            param = torch.tensor(param, device=device, dtype=torch.float64)\n",
    "        return param.to(dtype=torch.float64, device=device)\n",
    "    \n",
    "    xv = ensure_tensor(xv, device)\n",
    "    v = ensure_tensor(v, device)\n",
    "    A = ensure_tensor(A, device)\n",
    "\n",
    "    for i in range(0, len(points), batch_size):\n",
    "        # Keep original float64 dtype from CSV data\n",
    "        batch_points = points[i:i+batch_size]\n",
    "        points_tensor = torch.from_numpy(batch_points).to(\n",
    "            device=device,\n",
    "            dtype=torch.float64  # Maintain float64 precision\n",
    "        )\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=False):  # Disable mixed precision\n",
    "            batch_coords = STalign.transform_points_target_to_source(\n",
    "                xv, \n",
    "                v, \n",
    "                A, \n",
    "                points_tensor\n",
    "            )\n",
    "            all_coords.append(batch_coords.detach().cpu().numpy())\n",
    "            \n",
    "        del points_tensor, batch_coords\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return np.concatenate(all_coords)\n",
    "\n",
    "\n",
    "def perform_lddmm_alignment(he_image, cycif_image, L, T, params):\n",
    "    \"\"\"Perform optimized non-linear alignment\"\"\"\n",
    "    configure_gpu()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Filter valid LDDMM parameters\n",
    "    valid_params = {k: v for k, v in params.items() if k in ['sigmaM', 'sigmaB', 'sigmaA', 'epV', 'niter']}\n",
    "    \n",
    "    L_tensor = torch.from_numpy(L).float().to(device)\n",
    "    T_tensor = torch.from_numpy(T).float().to(device)\n",
    "    \n",
    "    he_data = torch.from_numpy(he_image['data']).half().to(device)\n",
    "    cycif_data = torch.from_numpy(cycif_image['data']).half().to(device)\n",
    "\n",
    "    base_params = {\n",
    "        'L': L_tensor,\n",
    "        'T': T_tensor,\n",
    "        'device': device,\n",
    "        'muB': torch.tensor([0, 0, 0], dtype=torch.float16, device=device),\n",
    "        'muA': torch.tensor([1, 1, 1], dtype=torch.float16, device=device)\n",
    "    }\n",
    "    base_params.update(valid_params)\n",
    "    \n",
    "    try:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return STalign.LDDMM(\n",
    "                [he_image['Y'], he_image['X']], he_data,\n",
    "                [cycif_image['Y'], cycif_image['X']], cycif_data,\n",
    "                **base_params\n",
    "            )\n",
    "    except RuntimeError as e:\n",
    "        if 'CUDA out of memory' in str(e):\n",
    "            print(\"Falling back to CPU with reduced resolution\")\n",
    "            return perform_cpu_fallback(he_image, cycif_image, L, T, params)\n",
    "        raise\n",
    "\n",
    "def perform_cpu_fallback(he_image, cycif_image, L, T, params):\n",
    "    \"\"\"CPU fallback implementation with reduced resolution\"\"\"\n",
    "    params['raster_resolution'] *= 2\n",
    "    XJ, YJ, rasterized = rasterize_cells(\n",
    "        cycif_image['X'], cycif_image['Y'], \n",
    "        params['raster_resolution']\n",
    "    )\n",
    "    \n",
    "    he_data = torch.from_numpy(he_image['data']).float()\n",
    "    cycif_data = torch.from_numpy(rasterized).float()\n",
    "    \n",
    "    return STalign.LDDMM(\n",
    "        [he_image['Y'], he_image['X']], he_data,\n",
    "        [YJ, XJ], cycif_data,\n",
    "        L=L, T=T,\n",
    "        device='cpu',\n",
    "        niter=params.get('niter', 1000)\n",
    "    )\n",
    "\n",
    "def save_results(df, transformed_coords, output_path):\n",
    "    \"\"\"Save results with automatic directory creation\"\"\"\n",
    "    try:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df['aligned_X'] = transformed_coords[:, 1]\n",
    "        df['aligned_Y'] = transformed_coords[:, 0]\n",
    "        \n",
    "        if output_path.suffix == '.gz':\n",
    "            df.to_csv(output_path, compression='gzip', index=False)\n",
    "        else:\n",
    "            df.to_csv(output_path, index=False)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to save results: {str(e)}\")\n",
    "\n",
    "def visualize_alignment(he_image, original, transformed, output_dir):\n",
    "    \"\"\"Generate alignment visualization\"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    ax[0].imshow(he_image['data'].transpose(1, 2, 0), extent=STalign.extent_from_x((he_image['Y'], he_image['X'])))\n",
    "    ax[0].scatter(original[:, 0], original[:, 1], s=1, alpha=0.1, c='red')\n",
    "    ax[0].set_title('Original Positions')\n",
    "    \n",
    "    ax[1].imshow(he_image['data'].transpose(1, 2, 0), extent=STalign.extent_from_x((he_image['Y'], he_image['X'])))\n",
    "    ax[1].scatter(transformed[:, 1], transformed[:, 0], s=1, alpha=0.1, c='white')\n",
    "    ax[1].set_title('Aligned Positions')\n",
    "    \n",
    "    plt.savefig(output_dir/'alignment_result.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        validate_paths()\n",
    "        configure_gpu()\n",
    "        \n",
    "        # Load data\n",
    "        he_data = load_he_image(PATHS['he_image'], PARAMS['rotation'])\n",
    "        YI = np.arange(he_data.shape[1]) * 1.0\n",
    "        XI = np.arange(he_data.shape[2]) * 1.0\n",
    "        he_image = {'data': he_data, 'X': XI, 'Y': YI}\n",
    "        \n",
    "        df, x_coords, y_coords = load_cell_data(PATHS['cell_data'])\n",
    "        \n",
    "        # Rasterize cells\n",
    "        XJ, YJ, rasterized = rasterize_cells(x_coords, y_coords, PARAMS['raster_resolution'])\n",
    "        cycif_image = {'data': rasterized, 'X': XJ, 'Y': YJ}\n",
    "        \n",
    "        # Alignment\n",
    "        points_he = load_landmarks(PATHS['landmarks_he'])\n",
    "        points_cycif = load_landmarks(PATHS['landmarks_cycif'])\n",
    "        L, T = initialize_alignment(points_he, points_cycif)\n",
    "        \n",
    "        result = perform_lddmm_alignment(he_image, cycif_image, L, T, PARAMS['lddmm'])\n",
    "        \n",
    "        # Batch transformation\n",
    "        points = np.stack([y_coords, x_coords], -1)\n",
    "        transformed_coords = batch_transform_points(\n",
    "            result['xv'], \n",
    "            result['v'], \n",
    "            result['A'],\n",
    "            points,\n",
    "            PARAMS['batch']['size']\n",
    "        )\n",
    "        \n",
    "        # Save and visualize\n",
    "        save_results(df, transformed_coords, PATHS['output'])\n",
    "        visualize_alignment(he_image, points, transformed_coords, PATHS['output'].parent)\n",
    "        \n",
    "        print(\"\\nSUCCESS: Alignment completed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{' ERROR '.center(50, '=')}\")\n",
    "        print(f\"FAILURE: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(f\"1. Try increasing 'max_split_size' parameter\")\n",
    "        print(f\"2. Reduce 'batch_size' in PARAMS['batch']\")\n",
    "        print(f\"3. Increase 'raster_resolution' in main PARAMS\")\n",
    "        print('='*50)\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
