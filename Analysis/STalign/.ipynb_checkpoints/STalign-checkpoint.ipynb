{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dce0116-f9d7-47ac-a98b-0703c74dbfae",
   "metadata": {},
   "source": [
    "# Installation and use of STalign\n",
    "\n",
    "Cruz Osuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a226c-8306-4ca8-9a6e-f327dc91d20d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## Setup\n",
    "\n",
    "\n",
    "` conda create --name STalign-env python=3.11` \n",
    "\n",
    "` conda activate STalign-env` \n",
    "\n",
    "` pip install --upgrade \"git+https://github.com/JEFworks-Lab/STalign.git\"` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f13f3-3a45-4126-b8d3-b86c3739c1bd",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f1ff6-9f1d-4268-a060-737bec4ccab8",
   "metadata": {},
   "source": [
    "### Create the .npz files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd447c-0852-4aea-8998-e9c784bc3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy.ndimage as ndimage\n",
    "from STalign import STalign\n",
    "\n",
    "# Parámetros\n",
    "image_file = \"T:/virtual_tma/FA/Images/FAHNSCC-14_he.png\"\n",
    "csv_file = \"T:/CycIF_human_2024/8_Results/Datasets/2_2_Phenotype_calling/FAHNSCC_14_phenotype_annotated.csv\"\n",
    "output_npz_image = \"T:/virtual_tma/FA/Points/npz/FAHNSCC_14\"\n",
    "output_npz_raster = \"T:/virtual_tma/FA/Points/npz/FAHNSCC_14_HE\"\n",
    "rotation_angle = 90  # grados\n",
    "dx = 5  # resolución de rasterización en µm\n",
    "\n",
    "# Leer imagen H&E\n",
    "V = plt.imread(image_file)\n",
    "V = ndimage.rotate(V, rotation_angle, reshape=True)\n",
    "\n",
    "# Visualizar imagen (opcional)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(V)\n",
    "\n",
    "# Transformar imagen a formato 3xNxM para STalign\n",
    "Inorm = V\n",
    "I = Inorm.transpose(2, 0, 1)\n",
    "YI = np.array(range(I.shape[1])) * 1.0\n",
    "XI = np.array(range(I.shape[2])) * 1.0\n",
    "extentI = STalign.extent_from_x((YI, XI))\n",
    "\n",
    "# Leer datos de células\n",
    "df = pd.read_csv(csv_file)\n",
    "xM = np.array(df['X_centroid'])\n",
    "yM = np.array(df['Y_centroid'])\n",
    "\n",
    "# Rasterizar puntos celulares a imagen\n",
    "XJ, YJ, M, fig = STalign.rasterize(xM, yM, dx=dx)\n",
    "ax = fig.axes[0]\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Convertir raster a imagen RGB simulada y normalizar\n",
    "J = np.vstack((M, M, M))\n",
    "J = STalign.normalize(J)\n",
    "\n",
    "# Verificar dimensiones\n",
    "print(\"Imagen H&E (I):\", I.shape)\n",
    "print(\"Imagen rasterizada (M):\", M.shape)\n",
    "print(\"Imagen RGB rasterizada (J):\", J.shape)\n",
    "\n",
    "# Guardar imágenes como .npz\n",
    "np.savez(output_npz_image, x=XI, y=YI, I=I)\n",
    "np.savez(output_npz_raster, x=XJ, y=YJ, I=J)\n",
    "\n",
    "# Visualización de puntos celulares (opcional)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xM, yM, s=1, alpha=0.2)\n",
    "plt.title(\"Distribución de células\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f7393-1351-4482-bf44-6150073d7e2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create the landmarck points\n",
    "\n",
    "Use the `point_annotator.py` script to generate the .npy files using the .npz files.\n",
    "\n",
    "`python point_annotator.py /path/H&E_image.npz /path/t-CycIF_image.npz` \n",
    "\n",
    "\n",
    "\n",
    "Examples: \n",
    "\n",
    "` python point_annotator.py /media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/landmarcks/FAHNSCC_14_HE.npz /media/cruz/TOSHIBA_EXT/virtual_tma/FA_try-2/landmarcks/FAHNSCC_14.npz`  \n",
    "\n",
    "\n",
    "` python point_annotator.py /media/cruz-osuna/Spatial/virtual_tma/ONCOSYS-OVA/STalign/Landmarck_points/H144_iOmeHE.npz /media/cruz-osuna/Spatial/virtual_tma/ONCOSYS-OVA/STalign/Landmarck_points/H144_iOme.npz`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f1c828-6efc-4cf0-8d84-f08fbd70e38d",
   "metadata": {},
   "source": [
    "### Run the alignement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e3ce8f4-073a-4b30-ac6a-c3a4b8526b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 5367575: field larger than field limit (131072)\n",
      "Skipping line 5372168: field larger than field limit (131072)\n",
      "Skipping line 5376761: field larger than field limit (131072)\n",
      "Skipping line 5381352: field larger than field limit (131072)\n",
      "Skipping line 5385945: field larger than field limit (131072)\n",
      "Skipping line 5390541: field larger than field limit (131072)\n",
      "Skipping line 5395132: field larger than field limit (131072)\n",
      "Skipping line 5399724: field larger than field limit (131072)\n",
      "Skipping line 5404315: field larger than field limit (131072)\n",
      "Skipping line 5408906: field larger than field limit (131072)\n",
      "Skipping line 5413501: field larger than field limit (131072)\n",
      "Skipping line 5418094: field larger than field limit (131072)\n",
      "Skipping line 5422685: field larger than field limit (131072)\n",
      "Skipping line 5427278: field larger than field limit (131072)\n",
      "Skipping line 5431869: field larger than field limit (131072)\n",
      "Skipping line 5436458: field larger than field limit (131072)\n",
      "Skipping line 5441048: field larger than field limit (131072)\n",
      "Skipping line 5445640: field larger than field limit (131072)\n",
      "Skipping line 5450230: field larger than field limit (131072)\n",
      "Skipping line 5454818: field larger than field limit (131072)\n",
      "Skipping line 5459411: field larger than field limit (131072)\n",
      "Skipping line 5463998: field larger than field limit (131072)\n",
      "Skipping line 5468585: ',' expected after '\"'\n",
      "Skipping line 5473171: field larger than field limit (131072)\n",
      "Skipping line 5480053: field larger than field limit (131072)\n",
      "Skipping line 5484646: field larger than field limit (131072)\n",
      "Skipping line 5489232: field larger than field limit (131072)\n",
      "Skipping line 5493816: field larger than field limit (131072)\n",
      "Skipping line 5498403: field larger than field limit (131072)\n",
      "Skipping line 5502988: field larger than field limit (131072)\n",
      "Skipping line 5507577: field larger than field limit (131072)\n",
      "Skipping line 5512166: field larger than field limit (131072)\n",
      "Skipping line 5516751: field larger than field limit (131072)\n",
      "Skipping line 5521336: field larger than field limit (131072)\n",
      "Skipping line 5525925: field larger than field limit (131072)\n",
      "Skipping line 5530511: field larger than field limit (131072)\n",
      "Skipping line 5535098: field larger than field limit (131072)\n",
      "Skipping line 5539685: field larger than field limit (131072)\n",
      "Skipping line 5544274: field larger than field limit (131072)\n",
      "Skipping line 5548862: field larger than field limit (131072)\n",
      "Skipping line 5553450: field larger than field limit (131072)\n",
      "Skipping line 5558040: field larger than field limit (131072)\n",
      "Skipping line 5562626: field larger than field limit (131072)\n",
      "Skipping line 5567213: field larger than field limit (131072)\n",
      "Skipping line 5571800: field larger than field limit (131072)\n",
      "Skipping line 5576385: field larger than field limit (131072)\n",
      "Skipping line 5580975: field larger than field limit (131072)\n",
      "Skipping line 5585561: field larger than field limit (131072)\n",
      "Skipping line 5590148: field larger than field limit (131072)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================== ERROR ======================\n",
      "FAILURE: Cell data error: Missing columns: X_centroid, Y_centroid\n",
      "\n",
      "Troubleshooting steps:\n",
      "1. Try increasing 'max_split_size' parameter\n",
      "2. Reduce 'batch_size' in PARAMS['batch']\n",
      "3. Increase 'raster_resolution' in main PARAMS\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cell data error: Missing columns: X_centroid, Y_centroid",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mload_cell_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(missing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df, np.array(df[\u001b[33m'\u001b[39m\u001b[33mX_centroid\u001b[39m\u001b[33m'\u001b[39m]), np.array(df[\u001b[33m'\u001b[39m\u001b[33mY_centroid\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: Missing columns: X_centroid, Y_centroid",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 300\u001b[39m\n\u001b[32m    297\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    299\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 260\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    257\u001b[39m XI = np.arange(he_data.shape[\u001b[32m2\u001b[39m]) * \u001b[32m1.0\u001b[39m\n\u001b[32m    258\u001b[39m he_image = {\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m: he_data, \u001b[33m'\u001b[39m\u001b[33mX\u001b[39m\u001b[33m'\u001b[39m: XI, \u001b[33m'\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m: YI}\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m df, x_coords, y_coords = \u001b[43mload_cell_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATHS\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcell_data\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# Rasterize cells\u001b[39;00m\n\u001b[32m    263\u001b[39m XJ, YJ, rasterized = rasterize_cells(x_coords, y_coords, PARAMS[\u001b[33m'\u001b[39m\u001b[33mraster_resolution\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mload_cell_data\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df, np.array(df[\u001b[33m'\u001b[39m\u001b[33mX_centroid\u001b[39m\u001b[33m'\u001b[39m]), np.array(df[\u001b[33m'\u001b[39m\u001b[33mY_centroid\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCell data error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Cell data error: Missing columns: X_centroid, Y_centroid"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "STalign-based H&E to t-CycIF Alignment Pipeline\n",
    "With GPU Memory Optimizations and Batch Processing\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy.ndimage as ndimage\n",
    "from pathlib import Path\n",
    "from STalign import STalign\n",
    "import os\n",
    "import warnings\n",
    "import csv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration - Update these paths as needed\n",
    "PATHS = {\n",
    "    'he_image': Path(r\"/media/cruz/Spatial/virtual_tma/ONCOSYS-OVA/STalign/H144_iOme2_PE_II_HE.png\"),\n",
    "    'cell_data': Path(r\"/media/cruz/Spatial/virtual_tma/ONCOSYS-OVA/STalign/data_20230616.csv\"),\n",
    "    'landmarks_he': Path(r\"/media/cruz/Spatial/virtual_tma/ONCOSYS-OVA/STalign/Landmarck_points/H144_iOmeHE_points.npy\"),\n",
    "    'landmarks_cycif': Path(r\"/media/cruz/Spatial/virtual_tma/ONCOSYS-OVA/STalign/Landmarck_points/H144_iOme_points.npy\"),\n",
    "    'output': Path(r\"/media/cruz/Spatial/virtual_tma/ONCOSYS-OVA/STalign/output/H144_iOme2_PE_II.csv.gz\")\n",
    "}\n",
    "\n",
    "PARAMS = {\n",
    "    'rotation': 90,\n",
    "    'raster_resolution': 10,\n",
    "    'lddmm': {\n",
    "        'sigmaM': 0.15,\n",
    "        'sigmaB': 0.10,\n",
    "        'sigmaA': 0.11,\n",
    "        'epV': 10,\n",
    "        'niter': 2000\n",
    "    },\n",
    "    'batch': {\n",
    "        'size': 5000,\n",
    "        'max_split_size': 128\n",
    "    }\n",
    "}\n",
    "\n",
    "def validate_paths():\n",
    "    \"\"\"Validate all paths before processing\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    for key in ['he_image', 'cell_data', 'landmarks_he', 'landmarks_cycif']:\n",
    "        path = PATHS[key]\n",
    "        if not path.exists():\n",
    "            errors.append(f\"Missing input file: {str(path)}\")\n",
    "        elif path.is_dir():\n",
    "            errors.append(f\"Expected file but found directory: {str(path)}\")\n",
    "\n",
    "    output_dir = PATHS['output'].parent\n",
    "    if not output_dir.exists():\n",
    "        errors.append(f\"Output directory does not exist: {str(output_dir)}\\nCreate it with:\\nmkdir -p '{str(output_dir)}'\")\n",
    "    elif not os.access(output_dir, os.W_OK):\n",
    "        errors.append(f\"Output directory not writable: {str(output_dir)}\\nCheck permissions with:\\nls -ld '{str(output_dir)}'\")\n",
    "\n",
    "    if errors:\n",
    "        raise RuntimeError(\"\\n\".join(errors))\n",
    "\n",
    "def configure_gpu():\n",
    "    \"\"\"Configure GPU settings for optimal memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = f'max_split_size_mb:{PARAMS[\"batch\"][\"max_split_size\"]}'\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def load_he_image(path, rotation=0):\n",
    "    \"\"\"Load and preprocess H&E image with memory optimization\"\"\"\n",
    "    try:\n",
    "        img = plt.imread(str(path))\n",
    "        if rotation != 0:\n",
    "            img = ndimage.rotate(img, rotation, reshape=True)\n",
    "        return STalign.normalize(img.transpose(2,0,1))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading H&E image: {str(e)}\")\n",
    "\n",
    "def load_cell_data(path):\n",
    "    \"\"\"Load single-cell data with validation and error handling\"\"\"\n",
    "    try:\n",
    "        # Handle bad lines and quoted fields\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            on_bad_lines='warn',  # Skip problematic lines with warning\n",
    "            quoting=csv.QUOTE_MINIMAL,\n",
    "            quotechar='\"',\n",
    "            engine='python'  # More flexible parser for messy files\n",
    "        )\n",
    "        \n",
    "        required = ['X_centroid', 'Y_centroid']\n",
    "        missing = [col for col in required if col not in df.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing columns: {', '.join(missing)}\")\n",
    "            \n",
    "        return df, np.array(df['X_centroid']), np.array(df['Y_centroid'])\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Cell data error: {str(e)}\")\n",
    "\n",
    "def rasterize_cells(x, y, resolution=5):\n",
    "    \"\"\"Convert coordinates to rasterized image\"\"\"\n",
    "    XJ, YJ, M, fig = STalign.rasterize(x, y, dx=resolution)\n",
    "    fig.axes[0].invert_yaxis()\n",
    "    J = np.vstack((M, M, M))\n",
    "    return XJ, YJ, STalign.normalize(J)\n",
    "\n",
    "def load_landmarks(path):\n",
    "    \"\"\"Load and convert landmark points\"\"\"\n",
    "    points = np.load(str(path), allow_pickle=True).tolist()\n",
    "    formatted = []\n",
    "    for k in points.keys():\n",
    "        formatted.append([points[k][0][1], points[k][0][0]])\n",
    "    return np.array(formatted)\n",
    "\n",
    "def initialize_alignment(points_he, points_cycif):\n",
    "    \"\"\"Calculate initial affine transformation\"\"\"\n",
    "    L, T = STalign.L_T_from_points(points_he, points_cycif)\n",
    "    return L, T\n",
    "\n",
    "\n",
    "def batch_transform_points(xv, v, A, points, batch_size=5000):\n",
    "    \"\"\"Transform points in batches with dtype consistency\"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    all_coords = []\n",
    "    \n",
    "    # Ensure transformation parameters are on correct device and dtype\n",
    "    def ensure_tensor(param, device):\n",
    "        if isinstance(param, (list, tuple)):\n",
    "            return [ensure_tensor(p, device) for p in param]\n",
    "        if not isinstance(param, torch.Tensor):\n",
    "            param = torch.tensor(param, device=device, dtype=torch.float64)\n",
    "        return param.to(dtype=torch.float64, device=device)\n",
    "    \n",
    "    xv = ensure_tensor(xv, device)\n",
    "    v = ensure_tensor(v, device)\n",
    "    A = ensure_tensor(A, device)\n",
    "\n",
    "    for i in range(0, len(points), batch_size):\n",
    "        # Keep original float64 dtype from CSV data\n",
    "        batch_points = points[i:i+batch_size]\n",
    "        points_tensor = torch.from_numpy(batch_points).to(\n",
    "            device=device,\n",
    "            dtype=torch.float64  # Maintain float64 precision\n",
    "        )\n",
    "        \n",
    "        with torch.cuda.amp.autocast(enabled=False):  # Disable mixed precision\n",
    "            batch_coords = STalign.transform_points_target_to_source(\n",
    "                xv, \n",
    "                v, \n",
    "                A, \n",
    "                points_tensor\n",
    "            )\n",
    "            all_coords.append(batch_coords.detach().cpu().numpy())\n",
    "            \n",
    "        del points_tensor, batch_coords\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    return np.concatenate(all_coords)\n",
    "\n",
    "\n",
    "def perform_lddmm_alignment(he_image, cycif_image, L, T, params):\n",
    "    \"\"\"Perform optimized non-linear alignment\"\"\"\n",
    "    configure_gpu()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    # Filter valid LDDMM parameters\n",
    "    valid_params = {k: v for k, v in params.items() if k in ['sigmaM', 'sigmaB', 'sigmaA', 'epV', 'niter']}\n",
    "    \n",
    "    L_tensor = torch.from_numpy(L).float().to(device)\n",
    "    T_tensor = torch.from_numpy(T).float().to(device)\n",
    "    \n",
    "    he_data = torch.from_numpy(he_image['data']).half().to(device)\n",
    "    cycif_data = torch.from_numpy(cycif_image['data']).half().to(device)\n",
    "\n",
    "    base_params = {\n",
    "        'L': L_tensor,\n",
    "        'T': T_tensor,\n",
    "        'device': device,\n",
    "        'muB': torch.tensor([0, 0, 0], dtype=torch.float16, device=device),\n",
    "        'muA': torch.tensor([1, 1, 1], dtype=torch.float16, device=device)\n",
    "    }\n",
    "    base_params.update(valid_params)\n",
    "    \n",
    "    try:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            return STalign.LDDMM(\n",
    "                [he_image['Y'], he_image['X']], he_data,\n",
    "                [cycif_image['Y'], cycif_image['X']], cycif_data,\n",
    "                **base_params\n",
    "            )\n",
    "    except RuntimeError as e:\n",
    "        if 'CUDA out of memory' in str(e):\n",
    "            print(\"Falling back to CPU with reduced resolution\")\n",
    "            return perform_cpu_fallback(he_image, cycif_image, L, T, params)\n",
    "        raise\n",
    "\n",
    "def perform_cpu_fallback(he_image, cycif_image, L, T, params):\n",
    "    \"\"\"CPU fallback implementation with reduced resolution\"\"\"\n",
    "    params['raster_resolution'] *= 2\n",
    "    XJ, YJ, rasterized = rasterize_cells(\n",
    "        cycif_image['X'], cycif_image['Y'], \n",
    "        params['raster_resolution']\n",
    "    )\n",
    "    \n",
    "    he_data = torch.from_numpy(he_image['data']).float()\n",
    "    cycif_data = torch.from_numpy(rasterized).float()\n",
    "    \n",
    "    return STalign.LDDMM(\n",
    "        [he_image['Y'], he_image['X']], he_data,\n",
    "        [YJ, XJ], cycif_data,\n",
    "        L=L, T=T,\n",
    "        device='cpu',\n",
    "        niter=params.get('niter', 1000)\n",
    "    )\n",
    "\n",
    "def save_results(df, transformed_coords, output_path):\n",
    "    \"\"\"Save results with automatic directory creation\"\"\"\n",
    "    try:\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df['aligned_X'] = transformed_coords[:, 1]\n",
    "        df['aligned_Y'] = transformed_coords[:, 0]\n",
    "        \n",
    "        if output_path.suffix == '.gz':\n",
    "            df.to_csv(output_path, compression='gzip', index=False)\n",
    "        else:\n",
    "            df.to_csv(output_path, index=False)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to save results: {str(e)}\")\n",
    "\n",
    "def visualize_alignment(he_image, original, transformed, output_dir):\n",
    "    \"\"\"Generate alignment visualization\"\"\"\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    ax[0].imshow(he_image['data'].transpose(1, 2, 0), extent=STalign.extent_from_x((he_image['Y'], he_image['X'])))\n",
    "    ax[0].scatter(original[:, 0], original[:, 1], s=1, alpha=0.1, c='red')\n",
    "    ax[0].set_title('Original Positions')\n",
    "    \n",
    "    ax[1].imshow(he_image['data'].transpose(1, 2, 0), extent=STalign.extent_from_x((he_image['Y'], he_image['X'])))\n",
    "    ax[1].scatter(transformed[:, 1], transformed[:, 0], s=1, alpha=0.1, c='white')\n",
    "    ax[1].set_title('Aligned Positions')\n",
    "    \n",
    "    plt.savefig(output_dir/'alignment_result.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        validate_paths()\n",
    "        configure_gpu()\n",
    "        \n",
    "        # Load data\n",
    "        he_data = load_he_image(PATHS['he_image'], PARAMS['rotation'])\n",
    "        YI = np.arange(he_data.shape[1]) * 1.0\n",
    "        XI = np.arange(he_data.shape[2]) * 1.0\n",
    "        he_image = {'data': he_data, 'X': XI, 'Y': YI}\n",
    "        \n",
    "        df, x_coords, y_coords = load_cell_data(PATHS['cell_data'])\n",
    "        \n",
    "        # Rasterize cells\n",
    "        XJ, YJ, rasterized = rasterize_cells(x_coords, y_coords, PARAMS['raster_resolution'])\n",
    "        cycif_image = {'data': rasterized, 'X': XJ, 'Y': YJ}\n",
    "        \n",
    "        # Alignment\n",
    "        points_he = load_landmarks(PATHS['landmarks_he'])\n",
    "        points_cycif = load_landmarks(PATHS['landmarks_cycif'])\n",
    "        L, T = initialize_alignment(points_he, points_cycif)\n",
    "        \n",
    "        result = perform_lddmm_alignment(he_image, cycif_image, L, T, PARAMS['lddmm'])\n",
    "        \n",
    "        # Batch transformation\n",
    "        points = np.stack([y_coords, x_coords], -1)\n",
    "        transformed_coords = batch_transform_points(\n",
    "            result['xv'], \n",
    "            result['v'], \n",
    "            result['A'],\n",
    "            points,\n",
    "            PARAMS['batch']['size']\n",
    "        )\n",
    "        \n",
    "        # Save and visualize\n",
    "        save_results(df, transformed_coords, PATHS['output'])\n",
    "        visualize_alignment(he_image, points, transformed_coords, PATHS['output'].parent)\n",
    "        \n",
    "        print(\"\\nSUCCESS: Alignment completed\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{' ERROR '.center(50, '=')}\")\n",
    "        print(f\"FAILURE: {str(e)}\")\n",
    "        print(\"\\nTroubleshooting steps:\")\n",
    "        print(f\"1. Try increasing 'max_split_size' parameter\")\n",
    "        print(f\"2. Reduce 'batch_size' in PARAMS['batch']\")\n",
    "        print(f\"3. Increase 'raster_resolution' in main PARAMS\")\n",
    "        print('='*50)\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
